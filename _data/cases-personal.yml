# Personal cases extracted from cases.yml
- title: The Mandolorian (Season 2)
  year: 2020
  img: MandoSeason2.jpg
  comp: The Third Floor Inc.
  desc: >
        <p> The Mandolorian TV series used substantial amounts of virtual production in the development. My role was to working as a Pipeline TD, to develop tools and features for Unreal Engine and it's use for Mando VP. </p>
        <p> In particular, a focus on C++ support and expansion of the Python API to integrate core Maya tools into the new Unreal Engine workflow. </p>
  type: film-tv
  short-desc:
    - Unreal tools for Mandalorian.
    - C++ and Python API.
    - Maya integration.

- title: Jingle Jangle
  year: 2019
  img: JingleJangle.jpg
  comp: The Third Floor Inc.
  role: Pipeline Technical Director
  type: film-tv
  desc: On Set Work, alongside the NCam Realtime team, to bring Motion Capture and N-Cam together.
  short-desc:
    - N-Cam On-Set 

- title: Mad Factory VR
  year: 2018
  img: MadFactory.jpg
  comp: The Third Floor Inc.
  role: Pipeline Technical Director
  type: game
  desc: Mad Factory VR is a fun VR game built for an arcade type gameplay. I acted as a Unreal Engine consultant for the project and assisted the immersive team with the core game logic and VR best-practices.
  short-desc:
    - Unreal Engine consultancy for arcade-style VR gameplay.
    - Assisted immersive team with core game logic.
    - Implemented VR best practices for development.

- title: Game of Thrones (Season 7 - 8)
  year: 2017
  img: got8.jpg
  comp: The Third Floor Inc.
  role: Pipeline Technical Director
  link: https://www.imdb.com/- title/tt0944947/
  desc: >
      <p> On Game of Thrones (Season 8), I designed and produced virtual production tools, mainly utilising VR, for previsualisation and shot-planning, 
      used for the more complex scenes, the primary tool being <a href=https://pathfinder.thethirdfloorinc.com/> Pathfinder</a>,
      which allows you to both both scout locations and to plan camera shots. </p>
      Epic Games has created a excellent write-up of our work which you can read here:
      <br>
      <br>
      <a href=https://www.unrealengine.com/en-US/spotlights/virtual-production-on-the-battlegrounds-of-game-of-thrones>  Game of Thrones Previs using Unreal Engine</a>
  type: film-tv
  short-desc:
    - VP tools & Pipeline Development
    - VR Tools for Virtual Scounting + shot-planning.

# - title: Planet of the Apes - Last Frontier
#   year: 2017
#   img: apes.jpg
#   comp: The Imaginarium Studios
#   role: Technical Director
#   type: game
#   desc: >
#       On the last frontier I created the inital pitchvis in Unreal Engine, which was a complete scene with lighting, motion capture, and characters.
#       Later in development I also helped with marketing material, in particular R&D into new mediums of delivery, such as 360 and VR.
#   short-desc:
#     - Created initial pitch vis in Unreal Engine with full scene integration.
#     - Developed marketing material and explored new delivery mediums.
#     - Pioneered use of 360 and VR in game development.

- title: Star Citizen - Squadren 42
  year: 2015
  img: Squadren42.jpg
  comp: The Imaginarium Studios
  role: Technical Director
  type: game
  desc: >
    Star Citizen's Squadren 42 was a very large project for me, taking place over two years. My role was to drive and manage the realtime visualisation. Since this was (at the time) a CryEngine game, the realtime was all performed in CryEngine, in the actual game client. 
    This allowed our realtime to closely reflect the end-result.
  short-desc:
    - Realtime visualisation in CryEngine
    - Motion Capture Operator
    - Shadow + Support Cinematics director

- title: The Ritual
  year: 2017
  img: Ritual.jpg
  comp: The Imaginarium Studios
  role: Technical Director
  type: film-tv
  desc: >
      For the Ritual I used Unreal Engine to build previs scenes to help plan the capture of more difficult shots, 
      these were then used with performance capture digital sets for character motion development for the digital avatar of the monster (All in Unreal).
  short-desc:
    - Built previs scenes in Unreal Engine
    - Performance capture prep and realtime setup.

- title: Battlefield 1 
  year: 2016
  img: battlefield1.jpg
  comp: The Imaginarium Studios
  role: Technical Director
  type: game
  desc: >
    Performance Capture, data cleanup and pipeline development
  short-desc:
    - Performance Capture Operator
    - Data cleanup.

- title: The Tempest
  year: 2016
  img: Tempest.jpg
  comp: The Imaginarium Studios
  role: Technical Director
  type: misc
  desc: >
    <p> 
      The Tempest was a massive project for me where performance capture was merged with traditional stage show control to produce a realtime avatar, driven live on stage, and controlled through external tools over network languages, mainly DMX, OSC, and PSN </p>
    </p>  
    I created the Unreal project and merged all the elements together, including all the state logic, visual changes, and materials and particle fx.
    
    <ul>
      <li> Write-up by Epic: <a href=https://www.unrealengine.com/en-US/blog/unreal-engine-brings-virtual-character-to-life-onstage-in-the-royal-shakespeare-companys-the-tempest _target=blank> Unreal Engine Brings Virtual Character to Life Onstage in The Royal Shakespeare Companyâ€™s The Tempest </a></li>
      <li> White Paper on the Mocap Employed <a href=&quot;https://cdn2.unrealengine.com/Unreal+Engine%2Fperformance-capture-whitepaper-final%2FUnreal-Engine_performance-capture-whitepaper_LPC_Whitepaper_final-7f4163190d9926a15142eafcca15e8da5f4d0701.pdf&quot; target=&quot;_blank&quot;> Choosing a real-time performance capture system </a> </li>
    </ul>
  short-desc:
    - Live performance capture with traditional stage controls.
    - Setup a 4x Unreal Engine system for realtime rendering.
    - Assisted with plugin development for DMX.

- title: Avengers 2 - Age Of Ultron
  year: 2015
  img: avengers.jpg
  comp: The Imaginarium Studios
  role: Technical Director
  type: film-tv
  desc: On Avengers 2 I was the P-Cap operator for a capture stage in Shepperton Studios, where I captured principal cast and stunt-work.
  short-desc:
    - Mocap Operator on-set at Shepperton Studios.
    - Captured principal cast and stunt work.

- title: Star Wars - Episode 7
  year: 2015
  img: StarWars7.jpg
  comp: The Imaginarium Studios
  role: Technical Director
  type: film-tv
  desc: >
        For Star Wars I worked in studio and on location as motion capture technician, and I also worked on location as IBC capture operator
  short-desc:
    - Motion capture technician in studio and on location.
    - IBC capture operator on-set.

- title: Dawn Of The Planet Of The Apes
  year: 2014
  img: film_apes.jpg
  comp: The Imaginarium Studios
  role: Technical Director
  type: film-tv
  desc: >
        For Apes 2, my work was based around the various pick-ups in performance capture for Andy Serkis.
  short-desc:
    - Focused on performance capture pick-ups for Andy Serkis.
    - Enhanced character animations through detailed motion capture.
    - Collaborated in a high-profile film production environment.

- title: Final Fantasy - Kingsglaive
  year: 2017
  img: Kingsglaive.jpg
  comp: The Imaginarium Studios
  role: Technical Director
  link: #
  type: film-tv
  desc: >
      On Kingsglaive I alternated between work as a performance capture operator, and as the realtime operator using motion builder.

- title: Dream
  year: 2021
  img: Dream.jpg
  comp: The Royal Shakespeare Company
  role: Lead Developer
  type: misc
  by-zd: true
  desc: >
    <p> <a href=https://dream.online/ _target=blank> Dream Website </a> </p>
    <p> Role: Lead Developer </p>
    <p> Dream is an online production performed live at Portsmouth Guildhall in March 2021. 
    The production combined the latest gaming and theatre technology to create a shared experience between audiences and actors, and featured an interactive symphonic soundtrack. </p>

- title: Beijing Olympics 2022
  img: Olympics22.png
  comp: Discovery / Eurosport Team UK
  role: Freelance Pipeline Developer
  link: #
  desc: >
    <p> I created a system for placing background npcs into any project, inc mocap import and retargetting, seeded randomised characters, 
    outfits and animations, with a focus to bring the digital sets to life. 
    This system has since been reused in other projects and easily adapted to new use cases. </p>
  type: film-tv
  by-zd: true
